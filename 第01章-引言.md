# 第1章 引言

*机器学习*是一类强大的可以从经验中学习的技术。  
*深度学习*

## 1.1 日常生活中的机器学习

数据集、参数  
任一调整参数后的程序被称为*模型*。  
通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。  
使用数据集来选择参数的元程序被称为*学习算法*。  
在机器学习中，*学习*是一个训练模型的过程。

## 1.2 机器学习的关键组件

* 可以用来学习的*数据*
* 如何转换数据的*模型*
* 一个*目标函数*， 用来量化模型的有效性
* 调整模型参数以优化目标函数的*算法*

### 1.2.1 数据

每个数据集由一个个*样本*组成，大多时候，它们遵循独立同分布。
样本有时候也叫*数据点*或*数据实例*，通常每个样本由一组称为*特征*或者*协变量*的属性组成。
机器学习会根据这些属性进行预测。

每个样本的特征类别数量都相同的时候，其特征向量是固定长度的，称为数据的*维数*。

深度学习的一个主要优势是可以处理不同长度的数据。

### 1.2.2 模型

深度学习与经典方法的区别：前者关注功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习。

### 1.2.3 目标函数

学习：模型自主提高完成某些任务的性能。  
目标函数（可优化的）：对模型优略程度的度量。  
通常定义一个目标函数，并希望优化它到最小值。因为越小越好，这些函数被称为*损失函数*。

### 1.2.4 优化算法

梯度下降算法

## 1.3 各种机器学习问题

### 1.3.1 监督学习

*监督学习*擅长在“给定输入特征”的情况下预测标签。  
每个“特征-标签”对都称为一个*样本*。  

#### 1. 回归（解决“有多少”的问题）

*回归*是最简单的监督学习任务之一。  
当标签取任意数值时，称之为回归问题，此时的目标是生成一个模型，使它的预测值非常接近实际标签值。  
最小化预测值和实际标签的差距，平方误差损失函数的最小化。

#### 2. 分类（解决“哪一个”问题）

*分类*问题希望模型能够预测样本属于哪个类别，称为类。  
二项分类、多项分类。  
分类问题的常见损失函数被称为*交叉熵*。
有一些分类任务的变体可以用用于*层次结构*，层次结构假定在许多类之间存在某种关系。并非所有的错误分类都是均等的。  
*层次分类*

#### 3. 标注问题

学习预测不相互排斥的类别的问题称为*多标签分类*。

#### 4. 搜索

学习算法需要输出有序的元素子集。  
PageRank

#### 5. 推荐系统

#### 6. 序列学习

输入和输出都是可变长度的序列。  

* (1) 标记和解析
* (2) 自动语言识别
* (3) 文本到语音
* (4) 机器翻译

### 1.3.2 无监督学习

数据中不含有“目标”的机器学习问题被称为*无监督学习*。

### 1.3.3 与环境互动

*离线学习*是所有的学习都是在算法与环境断开后进行的。  
*分布偏移*

### 1.3.4 强化学习

*强化学习*：使用机器学习开发与环境交互并采取行动。  
*深度强化学习*：将深度学习应用与强化学习的问题。  
强化学习的目标是是产生一个好的策略。  

强化学习的分类：  
* 马尔科夫决策过程：环境可被完全观测到。
* 上下文老虎机：状态不依赖之前的动作。
* 多臂老虎机：没有状态。